slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/workspace': No such file or directory: going to /tmp instead
W0401 06:49:25.699000 222604 torch/distributed/run.py:792] 
W0401 06:49:25.699000 222604 torch/distributed/run.py:792] *****************************************
W0401 06:49:25.699000 222604 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0401 06:49:25.699000 222604 torch/distributed/run.py:792] *****************************************
W0401 06:49:30.495000 150513 torch/distributed/run.py:792] 
W0401 06:49:30.495000 150513 torch/distributed/run.py:792] *****************************************
W0401 06:49:30.495000 150513 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0401 06:49:30.495000 150513 torch/distributed/run.py:792] *****************************************
W0401 06:49:30.495000 257732 torch/distributed/run.py:792] 
W0401 06:49:30.495000 257732 torch/distributed/run.py:792] *****************************************
W0401 06:49:30.495000 257732 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0401 06:49:30.495000 257732 torch/distributed/run.py:792] *****************************************
W0401 06:49:30.496000 200054 torch/distributed/run.py:792] 
W0401 06:49:30.496000 200054 torch/distributed/run.py:792] *****************************************
W0401 06:49:30.496000 200054 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0401 06:49:30.496000 200054 torch/distributed/run.py:792] *****************************************
