
=== Detailed Benchmark Report ===

This report compares the effects of different optimizations:
1. --fused-optimizer: Enables fused Adam optimizer for faster training
2. --compile: Uses torch.compile to optimize model execution
3. Sequence length: Compares default (2048) vs doubled (4096)

Performance metrics explanation:
- Tokens per second: Raw throughput of tokens processed
- TFLOPs: Hardware throughput (trillion floating point operations per second)
- MFU (%): Model FLOPS Utilization - how efficiently the GPU is utilized

   High MFU (40-50%): Good efficiency
   Low MFU (<20%): Potential bottlenecks (memory, kernels, communication)

Results:

Configuration	Tokens per second	TFLOPs	MFU (%)
baseline	6564.39	317.19	32.07
fused_optimizer	7607.64	367.60	37.17
compile	7052.85	363.51	36.76
fused_optimizer_compile	8376.45	431.73	43.65
seq_len_4096	7504.67	386.80	39.11
seq_len_4096_fused_optimizer	8197.91	422.53	42.72
seq_len_4096_compile	8082.20	442.60	44.75
seq_len_4096_fused_optimizer_compile	8980.90	491.82	49.73

Performance Comparison (relative to baseline):
